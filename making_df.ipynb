{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "667f16f4",
   "metadata": {},
   "source": [
    "<h1>В этом файле я составляю единый датасет из спаршенных ссылок и исходного датасета.<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9ad5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from fake_useragent import UserAgent\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import kaggle\n",
    "import time\n",
    "import json\n",
    "# С сайта https://selenium-python.readthedocs.io/getting-started.html#simple-usage\n",
    "# на всякий случай предварительно качаю всё\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61d69ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_u_gen():\n",
    "    with open(\"../All_data_files/ign.csv\", \"r\", encoding=\"utf-8\") as ign:\n",
    "        df = pd.read_csv(ign)\n",
    "        unique_genres = list(df[\"genre\"].unique())\n",
    "        uni_gen = [x for x in unique_genres if isinstance(x, str) and \", \" not in x]\n",
    "    return uni_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a2f8946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_u_pltf():\n",
    "    with open(\"../All_data_files/ign.csv\", \"r\", encoding=\"utf-8\") as ign:\n",
    "        df = pd.read_csv(ign)\n",
    "        unique_pltf = list(df[\"platform\"].unique())\n",
    "        uni_pl = [x for x in unique_pltf if isinstance(x, str)]\n",
    "    return uni_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5ae4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genres = find_u_gen()\n",
    "unique_platforms = find_u_pltf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3bbd1f",
   "metadata": {},
   "source": [
    "Далее будет достаточно много проверок. Страница с обзорами конкретно на игры не грузится дальше 17-ой страницы\n",
    "Поэтому пришлось парсить главную страницу со всеми обзорами. Таким образом у меня собрались ссылки вообще про всё\n",
    "Игры, фильмы и тд. Но мне нужны только игры. Поэтому я для каждого параметра (имя, счет, жанр, платформа) добавляла\n",
    "Доп проверки, так как у фильмов, например, точно не будет указана платформа (типа РС или Хbox).\n",
    "Таким образом я старалась отсеять лишние данные, которые точно не игры (тем же способом отсеялись и настолки, так как\n",
    "у них пропадает параметр имени). Возможно есть и более простой способ, но я не смогла его реализовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76b72513",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_data = np.array([])\n",
    "platform_data = np.array([])\n",
    "score_data = np.array([])\n",
    "genre_data = np.array([])\n",
    "year_data = np.array([])\n",
    "month_data = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "224da231",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_genres = np.array([])\n",
    "# теперь необходимо перейти по всем этим ссылкам. Дальше я буду работать отдельно с каждой страницей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9f56ed",
   "metadata": {},
   "source": [
    "<h1>Далее идет большой кусок кода, который я делала в Pycharm. При переносе сюда решила не прогонять заново, \n",
    "потому что это займет несколько часов<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417a1022",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (open(\"../All_data_files/ign_links_more.txt\", \"r\", encoding=\"utf-8\") as ign):\n",
    "    for link in ign:\n",
    "        url = link.strip()  # На всякий случай почитила ссылки от лишних символов (типа \\n в конце).\n",
    "        # Без стрипа выдает 404\n",
    "        resp = requests.get(url, headers={'User-Agent': UserAgent().chrome})\n",
    "        page_info = BS(resp.content, \"html.parser\")\n",
    "\n",
    "        # Тут достаем имя\n",
    "        try:\n",
    "            name_info = page_info.find(\"a\", {\"class\": \"jsx-4245402894 article-object-link underlined\"})\n",
    "            name_data = np.append(name_data, name_info.text)\n",
    "            print(name_info.text)\n",
    "        except Exception:\n",
    "            name_data = np.append(name_data, \"---\")\n",
    "            print(\"No name\")\n",
    "\n",
    "        # достанем счет\n",
    "        try:\n",
    "            score_info = page_info.find_all(\"div\", {\"class\": \"stack jsx-868863109 review-score-section\"})\n",
    "            game_score = score_info[0].div.figcaption.text\n",
    "            score_data = np.append(score_data, game_score)\n",
    "        except:\n",
    "            score_data = np.append(score_data, \"---\")\n",
    "            continue\n",
    "\n",
    "        # Имя и счет достали. Дальше достаем игровую платформу, дату, жанр\n",
    "        # Важно доставать платформу в последнюю очередь, потому что так удобнее вносить в таблицу\n",
    "        platform_info = page_info.find_all(\"script\", {\"id\":\"__NEXT_DATA__\"})\n",
    "        for script in platform_info:\n",
    "        # JSON string   ---  https://ru-brightdata.com/blog/how-tos-ru/parse-json-data-with-python\n",
    "            script = script.text\n",
    "            # from JSON string to Python dict\n",
    "            script_dict = json.loads(script)\n",
    "            # verify the type of the resulting variable\n",
    "            info_str = script_dict[\"props\"][\"pageProps\"][\"page\"][\"attributes\"]\n",
    "            if len(info_str) > 0:\n",
    "                for elem in info_str:\n",
    "                    try:\n",
    "                        game_genre = elem[\"attribute\"]['name']\n",
    "                        if game_genre in unique_genres:\n",
    "                            genre_data = np.append(genre_data, game_genre)\n",
    "                            break\n",
    "                        else:\n",
    "                            genre_data = np.append(genre_data, \"---\")\n",
    "                            break\n",
    "                    except Exception:\n",
    "                        game_genre = \"---\"\n",
    "                        genre_data = np.append(genre_data, \"---\")\n",
    "                        break\n",
    "            else:\n",
    "                game_genre = \"---\"\n",
    "                genre_data = np.append(genre_data, \"---\")\n",
    "            #достаем отсюда данные о платформах, на которых выпустится игра, год и месяц релиза и жанр\n",
    "            release_genre_str = script_dict[\"props\"][\"pageProps\"][\"page\"][\"primaryObject\"][\"objectRegions\"]\n",
    "            # проверки для года, месяца, платформы\n",
    "            # тут будет очень много проверок. Они могут показаться не нужными, но так вышло, потому что\n",
    "            # я парсила две разные страницы (общие обзоры и только игровые), которые отличалесь по своей структуре\n",
    "            # пришлось добавить несколько доп проверок\n",
    "            if release_genre_str and len(release_genre_str) > 0:\n",
    "                try:\n",
    "                    for elem in release_genre_str:\n",
    "                        date_list = []\n",
    "                        platf_list = []\n",
    "                        for i_elem in elem[\"releases\"]:\n",
    "                            platf_list.append(i_elem[\"platformAttributes\"][0][\"name\"])\n",
    "                            date_list.append(i_elem[\"date\"])\n",
    "\n",
    "                        date_list = [x for x in date_list if x is not None]\n",
    "                        platf_list = [x for x in platf_list if x is not None]\n",
    "                        release_date = max(date_list).split(\"-\")\n",
    "\n",
    "                        year = str(release_date[0])\n",
    "                        month = str(int(release_date[1]))\n",
    "                        # вот тут будем делать доп строки в случае, если игра на нескольких платформах\n",
    "                        # убираем мультиплатформы и те, которых нет в исходном датасете\n",
    "                        for i in platf_list:\n",
    "                            if i not in unique_platforms:\n",
    "                                platf_list.remove(i)\n",
    "\n",
    "                        if len(platf_list) > 0:\n",
    "                            for i_elem in range(0, len(platf_list)):\n",
    "                                platform_data = np.append(platform_data, platf_list[i_elem])\n",
    "                                year_data = np.append(year_data, year)\n",
    "                                month_data = np.append(month_data, month)\n",
    "\n",
    "                            for i_elem in range(0, len(platform_data) - len(name_data)):\n",
    "                                name_data = np.append(name_data, name_info.text)\n",
    "                                score_data = np.append(score_data, game_score)\n",
    "                                genre_data = np.append(genre_data, game_genre)\n",
    "\n",
    "                        else:\n",
    "                            platform_data = np.append(platform_data, \"---\")\n",
    "                            year_data = np.append(year_data, \"---\")\n",
    "                            month_data = np.append(month_data, \"---\")\n",
    "                except:\n",
    "                    platform_data = np.append(platform_data, \"---\")\n",
    "                    year_data = np.append(year_data, \"---\")\n",
    "                    month_data = np.append(month_data, \"---\")\n",
    "                    # На сайте указано много дат - для каждой платформы своя. Поэтому я решила брать самую\n",
    "                    # позднюю дату (чтоб наверняка)\n",
    "\n",
    "            else:\n",
    "                platform_data = np.append(platform_data, \"---\")\n",
    "                year_data = np.append(year_data, \"---\")\n",
    "                month_data = np.append(month_data, \"---\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37102b61",
   "metadata": {},
   "source": [
    "Итак, все данные для обогащения датасета собраны. Теперь надо собрать их в единую таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc050af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"title\":name_data, \"platform\":platform_data,\n",
    "                   \"score\":score_data, \"genre\":genre_data,\n",
    "                   \"release_year\":year_data, \"release_month\":month_data})\n",
    "df = df[df.isin([\"---\"]) == False]\n",
    "df = df.dropna()\n",
    "df.to_csv (r'try_more_data.csv', index= False )"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
